{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "417818ba-277e-47e0-b7da-ae3624d28f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "662fa61e-6dfa-4b47-af38-db0e208acf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v5'\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e939ba2e-c0d6-4b90-804f-06e47bc0081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geno_test_file = '../processed_data/test_geno_with_8_m_avg_all_data_{}.pkl'.format(version)\n",
    "pheno_test_file = '../processed_data/test_pheno_with_8_m_avg_{}.pkl'.format(version)\n",
    "\n",
    "geno_test_file_unique_env = '../processed_data/test_geno_unique_env_with_8_m_avg_all_data_{}.pkl'.format(version)\n",
    "pheno_test_file_unique_env = '../processed_data/test_pheno_uniqeu_env_with_8_m_avg_{}.pkl'.format(version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c89499b3-6586-439e-8e2c-6684acd628b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../processed_data/fc_model_env_middle_global_local_features_version_{}.pt'.format(version)\n",
    "pcc_model_path = '../processed_data/fc_model_env_pcc_middle_global_local_features_version_{}.pt'.format(version)\n",
    "target_scaler_path = '../processed_data/target_scaler_global_local_features_{}.pkl'.format(version)\n",
    "env_scaler_path = '../processed_data/env_scaler_global_local_features_{}.pkl'.format(version)\n",
    "training_output_path = '../outputs/env_middle_training_outputs_global_local_features_' + version + '.pkl'\n",
    "figure_loss_path = '../figures/loss_env_middle_global_local_features_' + version + '.jpeg'\n",
    "figure_pcc_path = '../figures/pcc_env_moddle_global_local_features_' + version + '.jpeg'\n",
    "test_output_all_env_path = '../outputs/predicted_all_env_global_local_features_' + version + '.pkl'\n",
    "test_output_unique_env_path = '../outputs/predicted_unique_env_global_local_features_' + version + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b7a88426-6940-40c1-b9fd-59178044c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_by_location(test_data):\n",
    "    locations = test_data['Loc_no'].unique()\n",
    "    trials = test_data['trial'].unique()\n",
    "\n",
    "    result_dict ={}\n",
    "    result_dict['location'] = []\n",
    "    result_dict['trial'] = []\n",
    "    result_dict['num_geno'] = []\n",
    "    result_dict['pcc'] = []\n",
    "\n",
    "    for location in locations:\n",
    "        for trial in trials:\n",
    "            partial_test = test_data[(test_data['Loc_no'] == location) & (test_data['trial'] == trial)]\n",
    "\n",
    "            if len(partial_test) > 20:\n",
    "               \n",
    "                pcc = pearsonr(partial_test['Value'].to_numpy().reshape(-1,), partial_test['predicted'].to_numpy().reshape(-1,))[0]\n",
    "                result_dict['location'].append(location)\n",
    "                result_dict['trial'].append(trial)\n",
    "                result_dict['num_geno'].append(len(partial_test))\n",
    "                result_dict['pcc'].append(pcc)\n",
    "   \n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "   \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c5c7c1ed-1736-484a-89dd-666af4b34010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(x, y, xlabel, ylabel, xlim=None, ylim=None, axis_range='equal'):\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "   \n",
    "    if xlim == None and axis_range == 'equal':\n",
    "        xlim = np.amin(x.tolist() + y.tolist()) - 0.5 , np.amax(x.tolist() + y.tolist()) +0.5\n",
    "        ylim =xlim\n",
    "    else:\n",
    "        xlim = np.amin(x) - 0.5 , np.amax(x) +0.5\n",
    "        ylim = np.amin(y) - 0.5 , np.amax(y) +0.5\n",
    "   \n",
    "    plt.xlim(xlim[0], xlim[1])\n",
    "    plt.ylim(ylim[0], ylim[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9fdfa9f3-2b2a-42b1-90b8-bd8465fd4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(x, xlabel, ylabel):\n",
    "    plt.figure(figsize=(16,8), dpi=600)\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.histplot(x, binwidth=0.1, binrange=(-1,1))\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.savefig('../figures/marker_env_concatenated_{}.jpeg'.format(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bccd6373-6ea3-4715-8747-f761cdc78fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_data(scaler, predicted):\n",
    "    rescaled = scaler.inverse_transform(predicted.reshape(-1,1))\n",
    "    \n",
    "    return rescaled.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c783bf55-47a3-40ee-a4cf-bdc47b6c2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCModel(nn.Module):\n",
    "    def __init__(self, num_env, num_geno, reduce_dim=2666, output_dim=1):\n",
    "        super(FCModel, self).__init__()\n",
    "\n",
    "        self.reduce_dim = reduce_dim\n",
    "        self.num_geno = num_geno\n",
    "        self.num_env = num_env\n",
    "\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(num_geno, reduce_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # self.maxpool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # self.maxpool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # self.maxpool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.fc4 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc5 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc6 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu6 = nn.ReLU()\n",
    "\n",
    "        self.fc7 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        self.fc8 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        self.fc9 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu9 = nn.ReLU()\n",
    "\n",
    "        self.fc10 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu10 = nn.ReLU()\n",
    "\n",
    "        self.fc11 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu11 = nn.ReLU()\n",
    "\n",
    "        self.fc12 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu12 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.fc13 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu13 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.fc14 = nn.Linear(reduce_dim, reduce_dim)\n",
    "        self.relu14 = nn.ReLU()\n",
    "        \n",
    "        self.fc15 = nn.Linear(reduce_dim, 54)\n",
    "        self.relu15 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.regress = nn.Linear(54, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        d = x\n",
    "\n",
    "        x = self.fc2(d)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(d)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = d + x\n",
    "        d = x\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = d + x\n",
    "        d = x\n",
    "        \n",
    "\n",
    "        x = self.fc6(x)\n",
    "        x = self.relu6(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        x = self.relu7(x)\n",
    "\n",
    "        x = d + x\n",
    "        d = x\n",
    "        \n",
    "        x = self.fc8(x)\n",
    "        x = self.relu8(x)\n",
    "\n",
    "        x = self.fc9(x)\n",
    "        x = self.relu9(x)\n",
    "\n",
    "        x = d + x\n",
    "        d = x\n",
    "        \n",
    "        x = self.fc10(x)\n",
    "        x = self.relu10(x)\n",
    "\n",
    "        x = self.fc11(x)\n",
    "        x = self.relu11(x)\n",
    "\n",
    "        x = d + x\n",
    "        d = x\n",
    "        \n",
    "        x = self.fc12(x)\n",
    "        x = self.relu12(x)\n",
    "\n",
    "        x = self.fc13(x)\n",
    "        x = self.relu13(x)\n",
    "        \n",
    "        x = self.fc14(x)\n",
    "        x = self.relu14(x)\n",
    "        \n",
    "        x = d + x\n",
    "        d = x\n",
    "        \n",
    "        x = self.fc15(x)\n",
    "        x = self.relu15(x)\n",
    "        \n",
    "        \n",
    "       \n",
    "        x = self.regress(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ed8f7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WheatDataset(Dataset):\n",
    "#     def __init__(self, geno_file, target_file, scaler=None, output_scaler=None):\n",
    "#         self.scaler = scaler\n",
    "#         self.output_scaler=output_scaler\n",
    "#         with open(geno_file, 'rb') as pfile:\n",
    "#             self.data = pickle.load(pfile)\n",
    "\n",
    "#         with open(target_file, 'rb') as pfile:\n",
    "#             self.target = pickle.load(pfile)\n",
    "        \n",
    "\n",
    "#         ind = self.target <= 10\n",
    "#         self.target = self.target[ind]\n",
    "#         self.data = self.data[ind]\n",
    "        \n",
    "#         #Remove this line to run with global + local marker set\n",
    "#         self.data = np.delete(self.data, np.arange(2000, 4052), axis=1)\n",
    "        \n",
    "        \n",
    "#         self.target_original_space = self.target\n",
    "#         self.target_original_space = self.target_original_space.reshape(-1,)\n",
    "\n",
    "#         self.target = self.target.reshape(-1, 1)\n",
    "\n",
    "#         print('number of markers: ', self.data.shape[1])\n",
    "#         print(np.average(self.target))\n",
    "#         print(np.max(self.target))\n",
    "\n",
    "#         if scaler == None:\n",
    "#             self.scaler= MinMaxScaler()\n",
    "#             self.data[:, -81:] = self.scaler.fit_transform(self.data[:, -81:])\n",
    "#         else:\n",
    "#             self.data[:, -81:] = self.scaler.transform(self.data[:, -81:])\n",
    "            \n",
    "#         if self.output_scaler == None:\n",
    "#             self.output_scaler = MinMaxScaler()\n",
    "#             self.target = self.output_scaler.fit_transform(self.target)\n",
    "#         else:\n",
    "#             self.target = self.output_scaler.transform(self.target)\n",
    "\n",
    "#         self.target = self.target.reshape(-1,)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.data.shape[0]\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, ind):\n",
    "#         return self.data[ind], self.target[ind], self.target_original_space[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "820a502b-9a3a-47dc-9b0b-71b7c563f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheatDataset(Dataset):\n",
    "    def __init__(self, geno_file, target_file, scaler=None, output_scaler=None):\n",
    "        self.scaler = scaler\n",
    "        self.output_scaler=output_scaler\n",
    "        with open(geno_file, 'rb') as pfile:\n",
    "            all_data = pickle.load(pfile)\n",
    "\n",
    "        all_data = all_data[all_data['Value'] <= 10]\n",
    "        \n",
    "        geno_data = all_data.iloc[:, 3:4055]\n",
    "        weather = np.array(all_data['weather'].tolist())\n",
    "        \n",
    "        self.target = all_data['Value'].to_numpy()\n",
    "        self.data = np.hstack((geno_data, weather))\n",
    "\n",
    "        self.locations = all_data['Loc_no'].to_numpy()\n",
    "        \n",
    "        self.trials = all_data['trial'].to_numpy()\n",
    "        \n",
    "        \n",
    "        self.target_original_space = self.target\n",
    "        self.target_original_space = self.target_original_space.reshape(-1,)\n",
    "\n",
    "        self.target = self.target.reshape(-1, 1)\n",
    "\n",
    "        print('number of markers: ', self.data.shape[1])\n",
    "        print(np.average(self.target))\n",
    "        print(np.max(self.target))\n",
    "\n",
    "        if scaler == None:\n",
    "            self.scaler= MinMaxScaler()\n",
    "            self.data[:, -81:] = self.scaler.fit_transform(self.data[:, -81:])\n",
    "        else:\n",
    "            self.data[:, -81:] = self.scaler.transform(self.data[:, -81:])\n",
    "            \n",
    "        if self.output_scaler == None:\n",
    "            self.output_scaler = MinMaxScaler()\n",
    "            self.target = self.output_scaler.fit_transform(self.target)\n",
    "        else:\n",
    "            self.target = self.output_scaler.transform(self.target)\n",
    "\n",
    "        self.target = self.target.reshape(-1,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        return self.data[ind], self.target[ind], self.target_original_space[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6823898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perf_measure(true, predicted):\n",
    "    pcc, pval = pearsonr(true, predicted)\n",
    "    \n",
    "    return pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "60dfe327-fe2a-468e-8596-31e8aed915ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    predicted = []\n",
    "    true = []\n",
    "    true_original_space = []\n",
    "    \n",
    "    eval_loss = 0\n",
    "    count = 0\n",
    "    for data, target, true_scaled in dataloader:\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        \n",
    "        target = target.float()\n",
    "        target = target.to(device)\n",
    "        \n",
    "        \n",
    "        outputs = model(data)\n",
    "        outputs= outputs.view(-1,)\n",
    "        \n",
    "        loss = criterion(target, outputs)\n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        predicted += outputs.detach().cpu().numpy().tolist()\n",
    "        true += target.detach().cpu().numpy().tolist()\n",
    "        true_original_space += true_scaled.numpy().tolist()\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    eval_loss = eval_loss / count    \n",
    "    predicted = np.array(predicted)\n",
    "    true = np.array(true)\n",
    "    \n",
    "    pcc = calculate_perf_measure(true, predicted)\n",
    "    \n",
    "    return eval_loss, pcc, np.array(true_original_space), predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7bef0-56d2-47bf-9ee1-09354fa75473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0cccd8aa-3604-4d12-a245-a433a2ddddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcc_loss(true, predicted):\n",
    "  x = predicted\n",
    "  y = true\n",
    "\n",
    "#   vx = x - torch.mean(x)\n",
    "#   vy = y - torch.mean(y)\n",
    "\n",
    "#   cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "  \n",
    "  x = torch.cat((true, predicted),0)\n",
    "  cost = torch.corrcoef(x)\n",
    "  cost = cost[0,1]\n",
    "  #v2 code added here\n",
    "  mse_loss = torch.mean((predicted -true)**2)\n",
    "\n",
    "  total_cost = (1 - cost) + mse_loss\n",
    "\n",
    "  return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "685dd18a-fdbd-47f9-a031-07ad8d138c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(env_scaler_path, 'rb') as infile:\n",
    "    env_scaler = pickle.load(infile)\n",
    "    \n",
    "with open(target_scaler_path, 'rb') as infile:\n",
    "    target_scaler = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3819d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(geno_test_file, 'rb') as infile:\n",
    "    test_data = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d25ec8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13111, 81)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(test_data['weather'].tolist())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4383fdfe-ead2-4ce9-a7f3-5c042dc5e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of markers:  4133\n",
      "4.812559639171196\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = WheatDataset(geno_test_file, pheno_test_file, env_scaler, target_scaler) \n",
    "# test_dataset_unique_env = WheatDataset(geno_test_file_unique_env, pheno_test_file_unique_env, env_scaler, target_scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0e385309-3200-4a8b-b905-cdfad7fef9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e0ee6793-6b12-4f50-9afc-4a7c4f8fbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_env = 81\n",
    "num_geno=test_dataset.data.shape[1]\n",
    "device = device\n",
    "reduce_dim=770\n",
    "model = FCModel(num_env, num_geno, reduce_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6cb49cf9-29a1-429f-a2ad-4c481d909913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d2942f0f-9b81-4adc-81f6-c62076fc71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.038121776926757105\n",
      "test pcc:  0.4179092120467102\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_pcc, true_original_space, predicted= evaluate(test_loader, model, criterion)\n",
    "print('test loss: ', test_loss)\n",
    "print('test pcc: ', test_pcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4a02d970-d4d7-42cb-92c5-ef13367b42b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4179092119525602"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_predicted = rescale_data(target_scaler, predicted)\n",
    "calculate_perf_measure(true_original_space, rescaled_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "68002806-84c3-45b7-bc67-b086db2bec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30213824, 0.43864411, 0.29407952, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.30213824, 0.43864411, 0.29407952, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.30213824, 0.43864411, 0.29407952, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.2028052 , 0.44730048, 0.2095086 , ..., 0.19037406, 0.46366871,\n",
       "        0.46116827],\n",
       "       [0.2028052 , 0.44730048, 0.2095086 , ..., 0.19037406, 0.46366871,\n",
       "        0.46116827],\n",
       "       [0.2028052 , 0.44730048, 0.2095086 , ..., 0.19037406, 0.46366871,\n",
       "        0.46116827]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "201b5f4c-28b2-4b57-9d22-1f4858384f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Loc_no': test_loader.dataset.locations,\n",
    "    'trial': test_loader.dataset.trials,\n",
    "    'Value': test_loader.dataset.target_original_space,\n",
    "    'predicted': rescaled_predicted\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8df37b01-12f0-4239-b56c-0876538fc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = get_res_by_location(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "37576d21-7429-4c55-af0c-ab1d36e0f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_histogram(result_df['pcc'].to_numpy(), xlabel='pcc', ylabel='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1f006ae2-b64b-4246-94bb-36419ef999ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((result_df['pcc'] > 0) & (result_df['pcc'] <=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0813c43f-1507-4d92-b2de-5ea09cbd03b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((result_df['pcc'] > 0.3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d88a013c-2ec9-48eb-bacd-8860a948301d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((result_df['pcc'] < 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a6b5c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of markers:  4133\n",
      "4.877422741189667\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = WheatDataset(geno_test_file_unique_env, pheno_test_file_unique_env, env_scaler, target_scaler) \n",
    "criterion = nn.MSELoss().to(device)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3a6b8557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.051154077186947686\n",
      "test pcc:  0.25802136073092075\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_pcc, true_original_space, predicted= evaluate(test_loader, model, criterion)\n",
    "print('test loss: ', test_loss)\n",
    "print('test pcc: ', test_pcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1802c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "78e3909ed91b8b2e826dd7eddb74471018e84739ce54ef6d33c0fa3cbf16517c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
